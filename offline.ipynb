{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import glob  \n",
    "from copy import deepcopy\n",
    "from random import sample\n",
    "import tkinter as tk\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera geometric calibration\n",
    "Camera calibration is used to obtain the camera parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "edges = []\n",
    "edges_count = 0\n",
    "current_image = None\n",
    "images_temp = []\n",
    "\n",
    "square_size = 25\n",
    "chessboard_shape = (9,6)\n",
    "train_images_path = 'train_images2'\n",
    "test_images_path = 'test_images'\n",
    "plots_path = 'plots'\n",
    "video_path = 'video/chessboard.mp4'\n",
    "\n",
    "VIDEO = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_warning(message_id):\n",
    "    # Define the possible messages\n",
    "    messages = {\n",
    "        'not_4_edges': \"You didn't select enough edges!\",\n",
    "        'train_empty': \"Train image folder is empty!\",\n",
    "        'test_empty': \"Test image folder is empty!\",\n",
    "    }\n",
    "\n",
    "    # Fetch the appropriate message\n",
    "    message = messages.get(message_id, \"Unknown Warning\")\n",
    "\n",
    "    # Create the main window\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Warning\")\n",
    "\n",
    "    # Create a label for the message\n",
    "    label = tk.Label(root, text=message, padx=20, pady=20)\n",
    "    label.pack()\n",
    "\n",
    "    # Start the GUI event loop\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_corners_selection(event, x, y, flags, params):\n",
    "    global edges, edges_count, current_image, images_temp\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and edges_count < 4:\n",
    "        edges.append((x, y))  # Append the new point\n",
    "        images_temp.append(deepcopy(current_image))\n",
    "        edges_count += 1\n",
    "\n",
    "        label = str(edges_count)\n",
    "        cv2.putText(current_image, label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Draw the circle on the new point\n",
    "        cv2.circle(current_image, edges[edges_count - 1], 3, (255, 0, 0), -1)\n",
    "\n",
    "        # Draw line to the previous point if more than one point is selected\n",
    "        if edges_count > 1:\n",
    "            cv2.line(current_image, edges[edges_count - 2], edges[edges_count - 1], (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Draw line to the first point if four points are selected\n",
    "        if edges_count == 4:\n",
    "            cv2.line(current_image, edges[0], edges[-1], (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"Manual Corners Selection\", current_image)\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN and edges_count > 0:\n",
    "        edges_count -= 1\n",
    "        edges.pop()  # Remove the last point\n",
    "        current_image = images_temp[edges_count]\n",
    "\n",
    "        cv2.imshow(\"Manual Corners Selection\", current_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_edges(corners):\n",
    "    # Calculate the centroid of the corners\n",
    "    centroid = np.mean(corners, axis=0)\n",
    "\n",
    "    # Sort corners and determine their relative position to the centroid\n",
    "    top = sorted([corner for corner in corners if corner[1] < centroid[1]], key=lambda point: point[0])\n",
    "    bottom = sorted([corner for corner in corners if corner[1] >= centroid[1]], key=lambda point: point[0], reverse=True)\n",
    "\n",
    "    # Concatenate top and bottom points\n",
    "    return np.array(top + bottom, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_chessboard_corners():\n",
    "    global edges, edges_count, chessboard_shape, current_image\n",
    "    \n",
    "    if edges_count != 4:\n",
    "        show_warning('not_4_edges')\n",
    "    \n",
    "    edges = sort_edges(edges)\n",
    "    print(edges)\n",
    "    \n",
    "\n",
    "    # Calculate the maximum width and height    \n",
    "    max_width = max(np.linalg.norm(edges[0] - edges[1]), \n",
    "                    np.linalg.norm(edges[2] - edges[3]))\n",
    "    max_height = max(np.linalg.norm(edges[1] - edges[2]), \n",
    "                     np.linalg.norm(edges[3] - edges[0]))\n",
    "\n",
    "    # Define the mapping coordinates for perspective transform\n",
    "    dest_points = np.float32([\n",
    "                             [0, 0],\n",
    "                             [max_width - 1, 0],\n",
    "                             [max_width - 1, max_height - 1],\n",
    "                             [0, max_height - 1]])\n",
    "    \n",
    "\n",
    "    # Compute the perspective transform matrix\n",
    "    p_matrix = cv2.getPerspectiveTransform(edges.astype(np.float32), dest_points)\n",
    "    inverted_p_matrix = np.linalg.inv(p_matrix)\n",
    "\n",
    "    # Horizontal and vertical step\n",
    "    w_step = max_width / (chessboard_shape[1] - 1)\n",
    "    h_step = max_height / (chessboard_shape[0] - 1)\n",
    "\n",
    "    projected_corners = []\n",
    "\n",
    "    # Compute each projected point\n",
    "    for y in range(0, chessboard_shape[0]):\n",
    "        for x in range(0, chessboard_shape[1]):\n",
    "            point = np.array([x * w_step, y * h_step, 1])\n",
    "            point = np.matmul(inverted_p_matrix, point)\n",
    "            # Divide each point by its Z component\n",
    "            point *= (1.0 / point[2])\n",
    "            # Append only the first 2 elements of each point\n",
    "            projected_corners.append(point[0:2])\n",
    "\n",
    "    return np.array(projected_corners, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_images_dimensions(directory):\n",
    "    # Get list of image file paths\n",
    "    image_paths = glob.glob(os.path.join(directory, \"*.jpg\")) \n",
    "    \n",
    "    # Initialize variables to store the dimensions\n",
    "    min_width, min_height = np.inf, np.inf\n",
    "    dimensions_set = set()\n",
    "    \n",
    "    # First pass to find dimensions and check uniformity\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            h, w = img.shape[:2]\n",
    "            dimensions_set.add((h, w))\n",
    "            min_width, min_height = min(min_width, w), min(min_height, h)\n",
    "\n",
    "    # Check if all images have the same dimensions\n",
    "    if len(dimensions_set) == 1:\n",
    "        print(\"All images have the same dimensions.\")\n",
    "        return img.shape\n",
    "    else:\n",
    "        print(\"Not all images have the same dimensions. Proceeding to crop.\")\n",
    "\n",
    "    images_shape = ()\n",
    "    \n",
    "    # Second pass to crop images\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            h, w = img.shape[:2]\n",
    "            if h > min_height or w > min_width:\n",
    "                # Calculate crop dimensions\n",
    "                top = (h - min_height) // 2\n",
    "                bottom = h - min_height - top\n",
    "                left = (w - min_width) // 2\n",
    "                right = w - min_width - left\n",
    "\n",
    "                # Crop and save the image\n",
    "                cropped_img = img[top:h-bottom, left:w-right]\n",
    "                cv2.imwrite(image_path, cropped_img)\n",
    "                \n",
    "    return cropped_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intrinsics_comparisons(mtxs, stds, out_dir_path):\n",
    "    if len(mtxs) != len(stds):\n",
    "        warn(\"[PLOT_INTRINSICS]: No plot will be generated because the number of camera intrinsics and standard deviations must be the same!\")\n",
    "        return False\n",
    "\n",
    "    # Create some lists containing the intrinsic parameters\n",
    "    x_focal_lengths = np.array([cm[0][0] for cm in mtxs])\n",
    "    y_focal_lengths = np.array([cm[1][1] for cm in mtxs])\n",
    "    x_center = np.array([cm[0][2] for cm in mtxs])\n",
    "    y_center = np.array([cm[1][2] for cm in mtxs])\n",
    "\n",
    "    # The x-axis values will correspond to the indices of the calibrations\n",
    "    x_axis = np.arange(len(mtxs))\n",
    "\n",
    "    # Create some lists containing the standard deviations for each intrinsic parameter\n",
    "    x_focal_lengths_stds = np.array([std[0][0] for std in stds])\n",
    "    y_focal_lengths_stds = np.array([std[1][0] for std in stds])\n",
    "    x_centers_stds = np.array([std[2][0] for std in stds])\n",
    "    y_centers_stds = np.array([std[3][0] for std in stds])\n",
    "\n",
    "    # Create a plot with 4 rows and one column\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=1, figsize=(6, 15))\n",
    "\n",
    "    # Define bar width\n",
    "    bar_width = 0.35\n",
    "\n",
    "    # Plot the results as bars\n",
    "    ax[0].set_title(\"Focal Length (Fx)\")\n",
    "    ax[0].bar(x_axis, x_focal_lengths, bar_width, color='black')\n",
    "    ax[0].errorbar(x_axis, x_focal_lengths, yerr=x_focal_lengths_stds, fmt='none', ecolor='r', capsize=5)\n",
    "\n",
    "    ax[1].set_title(\"Focal Length (Fy)\")\n",
    "    ax[1].bar(x_axis, y_focal_lengths, bar_width, color='black')\n",
    "    ax[1].errorbar(x_axis, y_focal_lengths, yerr=y_focal_lengths_stds, fmt='none', ecolor='r', capsize=5)\n",
    "\n",
    "    ax[2].set_title(\"Center Point (Cx)\")\n",
    "    ax[2].bar(x_axis, x_center, bar_width, color='black')\n",
    "    ax[2].errorbar(x_axis, x_center, yerr=x_centers_stds, fmt='none', ecolor='r', capsize=5)\n",
    "\n",
    "    ax[3].set_title(\"Center Point (Cy)\")\n",
    "    ax[3].bar(x_axis, y_center, bar_width, color='black')\n",
    "    ax[3].errorbar(x_axis, y_center, yerr=y_centers_stds, fmt='none', ecolor='r', capsize=5)\n",
    "\n",
    "    # Adjust the x-axis to display calibration labels\n",
    "    ax[0].set_xticks(x_axis)\n",
    "    ax[0].set_xticklabels([\"Calibration \" + str(i) for i in range(len(mtxs))])\n",
    "    \n",
    "    ax[1].set_xticks(x_axis)\n",
    "    ax[1].set_xticklabels([\"Calibration \" + str(i) for i in range(len(mtxs))])\n",
    "    \n",
    "    ax[2].set_xticks(x_axis)\n",
    "    ax[2].set_xticklabels([\"Calibration \" + str(i) for i in range(len(mtxs))])\n",
    "    \n",
    "    ax[3].set_xticks(x_axis)\n",
    "    ax[3].set_xticklabels([\"Calibration \" + str(i) for i in range(len(mtxs))])\n",
    "\n",
    "    # Save the plot in a .pdf file\n",
    "    plt.savefig(os.path.join(out_dir_path, \"intrinsic_params_runs_comparison.pdf\"))\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_camera_intrinsics_confidence(mtx, ret, std, calibration_name=\"\", rounding=3):\n",
    "    title = \"Confidence Of Estimated Camera Parameters\" if calibration_name == \"\" \\\n",
    "        else \"[\" + calibration_name + \"] Confidence Of Estimated Camera Parameters\"\n",
    "\n",
    "    print(title)\n",
    "    print(\"Overall RMS Re-Projection Error\", round(ret, 3))\n",
    "    print(\"Focal Length (Fx)\", round(mtx[0][0], rounding), \"\\tSTD +/-\", round(std[0][0], rounding))\n",
    "    print(\"Focal Length (Fy)\", round(mtx[1][1], rounding), \"\\tSTD +/-\", round(std[1][0], rounding))\n",
    "    print(\"Camera Center (Cx)\", round(mtx[0][2], rounding), \"\\tSTD +/-\", round(std[2][0], rounding))\n",
    "    print(\"Camera Center (Cy)\", round(mtx[1][2], rounding), \"\\tSTD +/-\", round(std[3][0], rounding), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_camera_params(images_info, image_shape, pattern_shape, square_size):\n",
    "\n",
    "    default_object_points = np.zeros((pattern_shape[0] * pattern_shape[1], 3), dtype=np.float32)\n",
    "    default_object_points[:, :2] = np.mgrid[0:pattern_shape[0], 0:pattern_shape[1]].T.reshape(-1, 2) \\\n",
    "                                   * square_size\n",
    "\n",
    "    image_points = list(map(lambda info: info[1], images_info))\n",
    "    object_points = [default_object_points for _ in range(len(image_points))]\n",
    "\n",
    "    return cv2.calibrateCameraExtended(object_points, image_points, image_shape, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate():\n",
    "    if VIDEO == False:\n",
    "        global current_image, edges, edges_count, chessboard_shape, train_images_path, test_images_path, square_size, plots_path\n",
    "        \n",
    "        train_images_path_list = glob.glob(os.path.join(train_images_path,'*.jpg'))\n",
    "        # test_images_path_list = glob.glob(os.path.join(test_images_path,'*.jpg'))\n",
    "        \n",
    "        if not train_images_path_list:\n",
    "            show_warning('train_empty')\n",
    "        \n",
    "        # if not train_images_path_list:\n",
    "        #     show_warning('test_empty')\n",
    "        \n",
    "        train_image_shape = uniform_images_dimensions(train_images_path)[:2]\n",
    "        \n",
    "        # test_image_shape = uniform_images_dimensions(test_images_path)\n",
    "            \n",
    "        images_info = []\n",
    "        \n",
    "        for image_path in train_images_path_list:\n",
    "            current_image = cv2.imread(image_path)\n",
    "            \n",
    "            \n",
    "            current_image = cv2.resize(current_image, (0,0), fx=0.5, fy=0.5)\n",
    "            \n",
    "            if current_image is None:\n",
    "                warn(\"Cannot load \" + image_path + \". It will be skipped!\")\n",
    "                continue\n",
    "        \n",
    "            # Convert the picture to grayscale and try to detect the chessboard corners automatically with cv2 function\n",
    "            gray = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)\n",
    "            found, coords = cv2.findChessboardCorners(gray, chessboard_shape, flags=cv2.CALIB_CB_ADAPTIVE_THRESH +\n",
    "                                                                                    cv2.CALIB_CB_NORMALIZE_IMAGE +\n",
    "                                                                                    cv2.CALIB_CB_FAST_CHECK +\n",
    "                                                                                    cv2.CALIB_CB_FILTER_QUADS)\n",
    "            if not found:\n",
    "                warn(f\"Cannot detect corners for image {image_path}. The corners will need to be extracted manually!\")\n",
    "\n",
    "                # Keep a cache of the same picture\n",
    "                images_temp.append(deepcopy(current_image))\n",
    "\n",
    "                # Show the corner selection window\n",
    "                cv2.imshow(\"Manual Corners Selection\", current_image)\n",
    "                cv2.setMouseCallback(\"Manual Corners Selection\", manual_corners_selection)\n",
    "\n",
    "                # Once the user is done then it's sufficient to press any key to proceed to the interpolation phase\n",
    "                while True:\n",
    "                    cv2.waitKey(0)\n",
    "                    if edges_count == 4:\n",
    "                        cv2.destroyAllWindows()\n",
    "                        break\n",
    "\n",
    "                # Corner interpolation phase\n",
    "                coords = interpolate_chessboard_corners()\n",
    "\n",
    "                # Set the current image equal to the first entry in the cache list\n",
    "                current_image = images_temp[0]\n",
    "\n",
    "                # Reset the cache, edges list and count\n",
    "                images_temp.clear()\n",
    "                edges = []\n",
    "                edges_count = 0\n",
    "        \n",
    "        \n",
    "            # Perform a refinement algorithm to the projected corner points\n",
    "            term_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1)\n",
    "            points = cv2.cornerSubPix(gray, np.array(coords).astype(np.float32), (11, 11), (-1, -1), term_criteria)\n",
    "                \n",
    "            images_info.append((found, points))\n",
    "                        \n",
    "            cv2.drawChessboardCorners(current_image, chessboard_shape, points, True)\n",
    "            cv2.imshow('Checkerboard Corners', current_image)\n",
    "            cv2.waitKey(350)\n",
    "        \n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "                \n",
    "        # Calibration run 1\n",
    "        print('Starting Calibration 1')\n",
    "        ret_1, mtx_1, dist_1, r_vecs_1, t_vecs_1, std_in_1, _, _ = estimate_camera_params(images_info, train_image_shape, chessboard_shape, square_size)\n",
    "\n",
    "\n",
    "        # Calibration run 2\n",
    "        images_info = list(filter(lambda info: info[0], images_info))\n",
    "        print('Starting Calibration 2')\n",
    "        ret_2, mtx_2, dist_2, r_vecs_2, t_vecs_2, std_in_2, _, _ = estimate_camera_params(sample(images_info, 10), train_image_shape, chessboard_shape, square_size)\n",
    "\n",
    "        # Calibration run 3\n",
    "        print('Starting Calibration 3')\n",
    "        ret_3, mtx_3, dist_3, r_vecs_3, t_vecs_3, std_in_3, _, _ = estimate_camera_params(sample(images_info, 5), train_image_shape, chessboard_shape, square_size)\n",
    "\n",
    "        log_camera_intrinsics_confidence(mtx_1, ret_1, std_in_1, \"Calibration 1\")\n",
    "        log_camera_intrinsics_confidence(mtx_2, ret_2, std_in_2, \"Calibration 2\")\n",
    "        log_camera_intrinsics_confidence(mtx_3, ret_3, std_in_3, \"Calibration 3\")\n",
    "        \n",
    "        plot_intrinsics_comparisons([mtx_1, mtx_2, mtx_3], [std_in_1, std_in_2, std_in_3], plots_path)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video.\")\n",
    "            return\n",
    "        \n",
    "        images_info = []\n",
    "        train_image_shape = None\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # End of video\n",
    "\n",
    "            # Resize for faster processing\n",
    "            frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "            if train_image_shape is None:\n",
    "                train_image_shape = frame.shape[:2][::-1]  # (width, height)\n",
    "\n",
    "            # Convert the picture to grayscale\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect chessboard corners\n",
    "            found, coords = cv2.findChessboardCorners(gray, chessboard_shape, flags=cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_FILTER_QUADS)\n",
    "            if found:\n",
    "                term_criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1)\n",
    "                coords = cv2.cornerSubPix(gray, coords, (11, 11), (-1, -1), term_criteria)\n",
    "                images_info.append((found, coords))\n",
    "\n",
    "                # Display corners\n",
    "                cv2.drawChessboardCorners(frame, chessboard_shape, coords, found)\n",
    "                cv2.imshow('Chessboard Corners', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Calibration runs\n",
    "        if images_info:\n",
    "            print('Starting Calibration')\n",
    "            # Run calibration with collected corner information\n",
    "            ret_1, mtx_1, dist_1, r_vecs_1, t_vecs_1, std_in_1, _, _ = estimate_camera_params(images_info, train_image_shape, chessboard_shape, square_size)\n",
    "            log_camera_intrinsics_confidence(mtx_1, ret_1, std_in_1, \"Calibration\")\n",
    "            plot_intrinsics_comparisons([mtx_1], [std_in_1], plots_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Calibration\n"
     ]
    }
   ],
   "source": [
    "calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
